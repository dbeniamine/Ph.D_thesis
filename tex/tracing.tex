%!TEX encoding=UTF-8 Unicode
\chapter{Collecting Memory Traces}

Memory traces are useful to understand and optimize the memory usage of an application.
Still, collecting such a trace is challenging as there is no hardware help comparable to performance counters to do it non intrusively.
Therefore, memory trace collection tools must work at the \gls{OS} or software level.

In this chapter we present our main contributions that consists in two different memory trace collection tools:
\begin{itemize}
    \item The first tool, called \gls{Tabarnac}, uses an instrumentation library to obtain a global overview of the memory usage.
It is designed specifically to inspect \gls{NUMA} relate issues, has a low overhead and lock free design.
This tool also provides simple yet meaningful visualizations.
\gls{Tabarnac} was published at \gls{VPA} 2015 a \gls{SC} workshop~\cite{Beniamine15TABARNAC}.
Furthermore it is distributed as a free software under the \gls{GPL} license: \url{https://github.com/dbeniamine/Tabarnac}.
This work is the result of a collaboration with M. Diener and P.O.A Navaux from the informatica team of the \gls{UFRGS}, Porto Alegre, Brazil.
    \item The second tool, \gls{Moca}, addresses the challenge of collecting \emph{detailed}, \emph{precise} and \emph{complete} memory traces (as defined in \ref{def:traces}) with temporal information.
It relies on an \gls{OS} level mechanism called page fault interception and injection.
This work is the subject of two Inria research reports~\cite{Beniamine15Memory,Beniamine16Moca} and has been submitted at \gls{PMBS} 2016, a \gls{SC} workshop.
As the previous tool, \gls{Moca} is distributed under the \gls{GPL} license: \url{https://github.com/dbeniamine/Moca}.
\end{itemize}

This chapter presents first the design and usage of \gls{Tabarnac} through a use case and discuss the obtain results, its overhead and limits in \sect{Tabarnac}.
Then we present the challenged raised \gls{Moca} and how it addresses them in \sect{Moca}.
Finally we provide an extensive comparison of our tools against state of the art memory trace tools in \sect{Tools-Comp}.


\section{Tabarnac: Global view of the memory usage}
\label{sec:Tabarnac}

\acrfull{Tabarnac} is our first attempt to collect memory traces and use them for performance optimizations.
As previous work~\cite{Beniamine13Cartographier} showed how difficult it is to capture \emph{complete} memory traces with temporal information, this tools focuses on the global behavior.
Furthermore it aims specifically at improving \gls{NUMA} related performance issues.

\subsection{Design}

On \gls{NUMA} machines, optimizing memory performances often means reducing the number of remote accesses.
Indeed, to optimize the performances a memory page must be mapped to a physical memory bank as close as possible to the threads that actually uses it.
Remote accesses are extremely slow and must therefore be limited to the minimum possible.
Therefore to optimize memory performances on \gls{NUMA} system, it is required to know how much each page is accessed by each thread.
\gls{Tabarnac} is designed to collect specifically this information.

\begin{algorithm}[htb]
    \begin{algorithmic}
        \Function{mem\_access}{unsigned long address, int threadId, char type}
            \State uint64\_t page = address >> page\_bits;
            \State accesses[threadId][page][type]++;
        \EndFunction
    \end{algorithmic}
    \caption{Handling of memory accesses by Tabarnac.}
    \label{alg:Tabarnac}
\end{algorithm}

\gls{Tabarnac} is based on Numalyze~\cite{Diener15Characterizing} instrumentation which rely on the \gls{Pin}~\cite{Luk05Pin} library.
This instrumentation is lock free by design: it traps on each memory accesses but only maintain two counters per pages and per threads, as details in \alg{Tabarnac}.
Numalyze was originally designed to estimate the efficiency of adaptive page mapping tools.
Indeed, such tools uses partial traces to decide online where to map memory pages.
Comparing the mapping obtained with a partial trace to the one obtained with the complete trace collected by Numalyze helps deciding the minimum size of partial trace required to decide on a page mapping.
We proposed to used theses traces for offline, interactive analysis.
Furthermore, as page number are not really meaningful for humans, we added contextual information to Numalyze traces.
Indeed, \gls{Tabarnac} also collects data structure information by three different means.
First, each time a thread is created, it compute its stack bounds and create a virtual structure named \texttt{Stack\#N} where $N$ is the thread~Id.
Then every time a binary file is loaded (main file or shared library), it inspect the binary, looking for static data structures.
Finally it intercept every call the \texttt{malloc} functions family, keeping track of data structures big enough.
Only structures that are bigger than one page (usually $4$Kib in current x86\_64 architectures) are recorded as our analysis granularity is the memory page. The data structure information (name, size and address) are only used to generate the visualization, after the end of the instrumentation.
The name detection of malloc'ed data structure is heuristic and based on source code analysis.

After tracing finishes, the tool generate three \texttt{csv} files.
The first contains the list of pages and the number of reads and writes per thread.
The second contains the list of structures with their names, sizes and start addresses, the last file contains the stacks size and addresses.
Then, a script which reads the trace, retrieves the page / data structure mapping and generates the final visualization presented in the next subsection.

\gls{Tabarnac} only depends on \gls{Pin} for the trace collection and \gls{R} for the visualization, and can be installed easily.
If all the R library required to generate the visualization are not present, it is able to install them automatically.
By default \gls{Tabarnac} generate the memory trace and the visualization, but the user can also choose to only generate the memory trace or the visualization.
This is useful for people who cannot install \gls{R} on the machine used to generate the trace.
Moreover it allows the user to customize the plots generate by the \gls{R} script.

%\subsection{Visualization}

Once the data collection phase is done, \gls{Tabarnac} uses a \gls{R-markdown} script to generate the visualization (as an HTML page).
This visualization provides a summary of the trace through several plots\footnote{
    A full example of \gls{Tabarnac}'s output is available at:\\ \url{http://dbeniamine.github.io/Tabarnac/examples}.}.
It aims at showing how pages are shared inside each data structures.
Therefore, it provides two types of plots, the first aims at showing the importance of each data structure.
While the second describe the sharing patterns inside these data structures.
Each plot is introduced by an explanation of its presentation, what common issues it can help to understand and provides suggestions on how to fix these issues.
The visualization starts with a small introduction, summarizing the main principles while developing for \gls{NUMA} machines, and shows the hardware topology of the analyzed machine extracted
with Hwloc~\cite{Broquedis10hwloc}.

After the introduction, the visualization focuses on the usage of data structures.
Some structures are not displayed if less than $0.01\%$ of the total accesses happen on them.
This is done to make the output more readable by focusing on the most important structures.
However, it is possible to ask \gls{Tabarnac} not to ignore these structures for a more detailed view.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{tabarnac/example_sz}
        \caption{Structures size.}
        \label{fig:example_sz}
    \end{subfigure}
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{tabarnac/example_rw}
        \caption{Number of accesses per structures.}
        \label{fig:example_rw}
    \end{subfigure}
    \caption{Global views of the memory usage.}
    \label{fig:example_plot1}
\end{figure}

The first series of plots presents information concerning the relative importance of the data structures.
It consists of two plots, showing first the size of each data structure, as in Figure~\ref{fig:example_sz}, then the number of reads and writes in each structure (Figure~\ref{fig:example_rw}).
These plots give a general idea of the structures used by the parallel application.
Moreover, knowing the read/write behavior is very useful as it determines the possible optimizations.
For instance, small data structures written only during initialization (or very rarely) can be relatively easily
duplicated, such that each \gls{NUMA} node works on a local copy.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{tabarnac/example_ft}
        \caption{First touch distribution.}
        \label{fig:example_ft}
    \end{subfigure}
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{tabarnac/example_dist}
        \caption{Per thread access distribution.}
        \label{fig:example_dist}
    \end{subfigure}
    \caption{Per structure view of the memory usage.}
    \label{fig:example_by_structs}
\end{figure}

The second series of plots is the most important one.
It shows for each page of each structure which thread was responsible for the first touch (Figure~\ref{fig:example_ft}).
This information is important as the default policy for \gls{Linux} and most other operating systems is to map a page as close as possible to the first thread accessing it.
If the first touch distribution does not fit the actual access distribution, the default mapping performed by \gls{Linux} might not be efficient.
To address this issue, the developer can either correct the first touch or do some manual data mapping to ensure better memory access locality and balance during the execution.

Finally, \gls{Tabarnac} shows the density of accesses performed by each thread and the global distribution.
In the example shown in Figure~\ref{fig:example_dist}, each horizontal line represents the number of accesses to one page, there is one line per thread and one for the average number of accesses.
Moreover, for each thread the average number of accesses to the structure is displayed.
Darker lines indicate more memory accesses to the page. This visualization gives an easy way to understand the data sharing between threads, as well as the balance between pages and
threads.
These plots can be used to identify inefficient memory access behaviors and to determine the best \gls{NUMA} mapping policy.

\subsection{Case study}

\Input{tabarnac-expe}


\section{Moca: Collecting fine grain traces}
\label{sec:Moca}

As many tools, \gls{Tabarnac} sees the memory as a set of pages, loosing information at a finer granularity.
This approximation enable to trace memory accesses at a reduced cost.
Still, it only keeps one counter per page and per threads in order to reduce its overhead.
While this approach provides a deeper insight about the memory use than hardware performance counters, it lacks temporal information.

\subsection{Page faults interception}

Page faults interception can provide useful online information about memory usage.
Such a mechanism has been used in several existing works : in parallel garbage collectors~\cite{Boehm91Mostly}, in memory checkpointing~\cite{Heo05Spaceefficient} or in the domain of virtualization to provide the hypervisor with information about the memory usage of the guest \gls{OS}~\cite{Jones06Geiger}.
However, page faults only occur when caused by predetermined events in the system (copy-on-write, paging, ...).
Thus, just intercepting existing page faults only provide an approximate view of the memory use.
To improve this method, it is also possible to fake invalid pages at regular intervals in order to generate false page faults~\cite{Bae12Dynamic,Diener13CommunicationBased}.
These false page faults are just triggered during regular memory accesses, that would not have caused a page fault if the page were not faked as invalid.
The advantage is that they create additional events for the monitoring tool to collect, thus more \emph{precision}, but the set of faked invalid pages has to be known and maintained by the monitoring tool.

Existing memory profiling tools do not use false page faults injection and only need to store the location of memory pages and the threads that access them.
As a consequence, they require a relatively small data structure in memory for their own usage.
\gls{Moca} is a new \emph{complete} memory trace collection system, based on page fault interception and false page faults injection, able to capture \emph{precisely} the temporal evolution of memory accesses performed by a multithreaded application.
To reach a satisfying \emph{precision}, \gls{Moca} has to maintain in memory both the trace data and the set of faked invalid pages.
Overall, storing and exploiting efficiently these data within the kernel space and outputting them in real time to the user space is a challenge and is the main contribution of our work.

%\subsection{Design}

\gls{Moca} consist of a Linux kernel module that can be loaded at runtime,  a script in charge of both loading this module with the proper parameters and launching the monitored application on the user behalf and an optional library able retrieve data structures information.
It neither relies on architecture specific technologies such as \gls{AMD} \gls{IBS} or \gls{Intel} \gls{PEBS}, nor on architecture dependent kernel code, kernel patch or kernel modifications.
Therefore it is portable and can be run on any Linux kernel from the $3.0$.

Two tasks are addressed by the kernel module included in \gls{Moca}.
The first one is to keep track of the set of pages accessed by the application during an elementary monitoring interval.
The second one is to manage the huge quantity of data produced by the trace collection within the kernel space in-between regular flushes toward the user space.
Of course, these two tasks should be as slightly intrusive as possible.

When the user request to retrieve data structure informations, \gls{Moca} runs the application twice with virtual address space randomization disabled.
The first time, our library is preloaded before launching the application, the second time, the \gls{Moca} module is loaded but without the preloaded library is disabled.
This library reads static data structures information in each executed binary file and stores data about structures larger than one page.
It also intercepts all calls to \texttt{malloc} family functions and names these calls according to their stack trace.
\gls{Moca} and the library are run separately as \gls{Moca} is not able to differentiate the normal behavior of an application to the work done by the library.
Our context library is lightweight, the added cost is the cost of a regular execution added to a small constant overhead for each binary opened and each allocation performed.
Thus the overhead of using \gls{Moca} and the library is basically \gls{Moca} overhead plus one time the normal execution time.

\subsection{Trace collection}

\gls{Moca} collects \emph{complete} traces in the sense that the exact set of pages accessed by the application is deduced from the collected events at all times during the execution.
Thus, it is \emph{complete} at the page granularity.
Other information such as exact addresses and access times are a sample of the set of all the accesses.

In recent Linux kernel, physical memory pages are lazily allocated to page frames during the execution.
The first access to a page in the virtual address space triggers a page fault.
To handle this page fault, Linux allocates a physical page to the requested page frame.
Such a page fault can also be triggered when a thread access a shared page modified by another thread.
\gls{Moca} is built upon the possibility to register an additional callback on Linux page faults.

Nevertheless, a page fault does not occur at each memory access.
To monitor memory accesses during the course of the execution, we need to reenable a page fault similar to the first access, but performed on a regular basis and on behalf of \gls{Moca}.
In other words, we need to inject false page fault by periodically marking as \emph{not present} the pages accesses by the application.
In Linux terminology, this means that any access to the page will trigger a page fault which will have to be handled, in this case, by a handler contained in \gls{Moca}.

This method has several advantages over hardware sampling or instrumentation.
First, it provides a superset of all the memory accesses, because it guarantees that each page accessed by the monitored application will fault once and will be traced.
Thus, at the end of each monitoring interval, we know the exact set of accessed pages from which we deduce a superset of actual memory accesses.
This comes in addition to the fact that each false page fault generated provides \gls{Moca} with exact information about one memory access.
This means that \gls{Moca} also performs a sampling of all the memory accesses.
Because it is designed to manage large chunks of trace data within the kernel space, it also stores all the details about these samples in the collected trace.

\gls{Moca} differs from instruction sampling because it is not necessary to increase the monitoring frequency of \gls{Moca} to collect a \emph{complete} trace.
On the contrary, when using instruction sampling, if the pages of the application are accessed in an unbalanced manner, it is necessary to increase the sampling frequency to get a precise picture of the memory working set of the application.
Nevertheless, there can be no guarantee that a chosen sampling frequency will result in a trace that contains all the pages on which the application works.

\gls{Moca} also differs from instrumentation based tools because, just as in the case of sampling, memory accesses that are not collected in the trace are not trapped at all by a false page fault.
Furthermore, the remaining memory accesses, which are collected, are trapped using a hardware mechanism and Linux kernel probes.
Both are lightweight mechanisms, which means that the overall instrumentation overhead of \gls{Moca} is likely to be low.
Indeed, instrumentation based methods often work at a high granularity, collecting few information, in order to keep their naturally high overhead in control.

\subsection{Data management}

In this section we present in details how the main components of \gls{Moca} interact and how \gls{Moca} addresses the management of data it collects within the kernel space.
During the execution, \gls{Moca} needs to store three kinds of information:

\begin{enumerate}
    \item The set of \emph{tasks} (Linux internal representation of threads and processes) which are
monitored.
    This is necessary because page faults will also be triggered by other tasks which do not belong to
    the monitored application.
    \item The set of all page faults which have been injected by \gls{Moca}, required to distinguish false page faults from regular ones, because their handling differs.
    \item The set of addresses recently accessed by each task, this set correspond to the actual memory trace.
        It is required to keep it in kernel space as we need to reinject these false page faults at the end of each monitoring interval.
        Afterwards, this set is transferred to the user space by a dedicated process and appended to the resulting trace.
\end{enumerate}

\begin{figure}[htb]
    \centering
    \input{tikz/moca-tikz.tex}
    \caption{Interactions betweens Moca and Linux.}
    \label{fig:moca}
\end{figure}

The first two types of information are stored in preallocated hashmaps in order to reduce the runtime overhead of their management.
These hashmaps are read at each page fault but rarely written, only when a new task of the monitored application triggers its first page fault or when \gls{Moca} creates new false page faults.
We can protect them with Linux kernel built-in \emph{rwlocks}.
The third type of information is the actual trace, divided, for each task, in a private set of \emph{chunks}.
A chunk is the set of accesses that have been collected during the monitoring time interval.
Chunks provide a discretization of time, each chunk embed two timestamp to delimit its temporal bounds.
To reduce the volume of information stored, the accesses are not timestamped.
However, their order in the trace file is their order of arrival in the chunk.

The discretization of time, materialized as a sequence of chunks, is useful as it let the different components of \gls{Moca} work concurrently on different chunks.
Indeed, the traced program always works on \emph{current} chunks, one for each core, while the logging daemon, which flushes the trace from memory to permanent storage works on \emph{completed} chunks.
A monitoring kernel thread, manages the progress of this logical time.
It periodically wakes up, marks the current chunks as \emph{ending} and invalidates all the pages they reference.
Once all pages of the \emph{ending} chunks have been invalidated, it marks these chunks as \emph{completed}.
Finally, the logging process flushes \emph{completed} chunks to the filesystem at a lower rate, in order to reduce the overhead of I/Os requests, and recycle them as empty places for upcoming chunks.
%\GH{Pourquoi à un rythme moins élevé ??? En théorie des files d'attentes ce genre de choses = débordement...}
%\DB{L'idée était de limiter la bande passante disque, et croiser les doigt pour que les files soient assez grosses \ldots Il faudrait essayer un logging interval très petit sur MG.}
%\GH{On peut aussi éventuellement rajouter les trois mots précédents, histoire de dire que le but est de factoriser les requêtes, pas de remplir la mémoire}
 \fig{moca} depicts the interaction between the different processes and threads of \gls{Moca}, its data structures and Linux.

Eventually, \gls{Moca} generates one csv file, each line of this file describe one access giving its physical and virtual address, the number of read and writes captured, a bitmask indicating on which CPU the access occurred, the start and end timestamp of its chunk and the internal identifier of the task which triggered it.
A set of access sharing the same timestamps and task identifier correspond to a chunk.
The order of accesses inside a chunk is preserved.

\begin{algorithm}[htb]
    \caption{Monitoring thread algorithm}
    \label{algo:monTh}
    \begin{algorithmic}[1]
        \While{\Callp{NotFinished}{}}
            \ForAll{t in \Callp{MonitoredTasks}{}}
                \State \Callp{EndCurrentChunk}{t}
                    \ForAll{Addr in \Callp{PreviousChunk}{t}}
                        \State \Callp{WriteLockPF}{}
                        \State \Callp{AddFalsePF}{Addr}
                        \State \Callp{WriteUnlockPF}{}
                    \EndFor
                \State \Callp{MarkPreviousChunkFinished}{t}
            \EndFor
            \State \Callp{sleep}{MonitorThreadWakeUpInterval}
        \EndWhile
    \end{algorithmic}
\end{algorithm}

The monitoring thread is a kernel thread that uses the algorithm~\ref{algo:monTh}, is in charge of enabling false page faults destined for \gls{Moca}.
It performs its task by removing the \texttt{PRESENT} flags from the \texttt{Page Table Entry} (\texttt{PTE}) that corresponds to each recently accessed addresses.
Of course, the shorter is the period between two wakeups, the more precise the trace is.
This period is called \emph{monitor thread wakeup interval} (or \emph{monitor interval}).
But invalidating all the recently accessed pages takes time as it requires to take a write lock on the page faults hashmap.
This write lock delays any pending false page fault in the monitored application.
Thus the wakeup frequency of the monitoring thread cannot be too high, otherwise its action becomes too intrusive.
The \texttt{MonitorThreadWakeUpInterval} \gls{Moca} parameter lets the user change the default setting that we have empirically chosen after a few experiments.

\begin{algorithm}[htb]
    \caption[Moca Logging daemon algorithm.]{Logging daemon algorithm.\\
        \footnotesize{Note that no locks are required to work on completed chunks.}}
    \label{alg:moca-log}
    \begin{algorithmic}[1]
        \While{\Callp{NotFinished}{}}
        \ForAll{t in \Callp{MonitoredTasks}{}}
                \ForAll{c in \Callp{FinishedChunks}{t}}
                \State \Callp{WriteTraceToDisk}{c}
                \State \Callp{ReinitChunk}{c}
                \EndFor
            \EndFor
            \State \Callp{sleep}{LoggingDaemonWakeupInterval}
        \EndWhile
    \end{algorithmic}
\end{algorithm}

The logging daemon that uses \alg{moca-log}, is a userspace process which periodically reads \texttt{/proc} pseudo files used by \gls{Moca} kernel module to export its data to userspace.
Those reads trigger a callback method in our tool which flush completed chunks from memory to disc.
As it works on completed chunks, it does not directly interfere with the normal application execution.
Especially, no lock is required to access to these completed chunks, and, as it mostly generates disc I/O, it does not compete much for CPU.
\gls{Moca} has just to wake him up sufficiently often so that the kernel module does not run out of free space to store upcoming chunks.

%\begin{algorithm}[htb]
%    \caption{Page fault handler}
%    \label{algo:PageFault}
%    \begin{algorithmic}[1]
%        \Function{HandleFault}{task t,void *addr, int type}
%            \If {\Callp{IsNotMonitoredTask}{t}}
%                \If {!\Callp{AddToMonitoredIfNeeded}{t}}
%                    \State \Return \Comment{Resume page fault}
%                \EndIf
%            \EndIf
%            \State \Callp{AddToChunk}{t,addr, type}
%            \Comment{Trace the access}
%            \State \Callp{ReadLockPF}{}
%            \State \Callp{TryFixFalsePageFault}{addr}
%            \State \Callp{ReadUnlockPF}{}
%            \State \Callp{UpdateClock}{}
%            \State \Comment{Resume page fault. If a fix occurred, Linux will
%                silently abort the page fault}
%        \EndFunction
%    \end{algorithmic}
%\end{algorithm}

\begin{figure}[htb]
    \centering
    \input{tikz/moca-fpf.tex}
    \caption{Flow chart of Moca's page faults}
    \label{fig:fpf-flow}
\end{figure}

Each time a page fault occurs, it is trapped by the handler registered by \gls{Moca}, which first finds out if the task (thread or process) involved by the page fault is monitored or not.
If not, it has to check if the task is a child of a monitored task and, in this case, it starts monitoring it.
The check be done with a simple read lock on the hashmap containing the monitored tasks, and the write lock is only taken if the task must be added.
This last case occurs only at the first page fault from a new monitored process or thread which is quite rare and usually occurs only at initialization time.
For instance, in the benchmarks used for the evaluation it happens $8$ times out of $5\times10^6$ accesses.
At the end of this phase, if the task is still not monitored, we let Linux handle the page fault as usual.
This behavior is depicted by \fig{fpf-flow}.

When a monitored task triggers a page fault, the access is first added to its current chunk.
For each access, \gls{Moca} stores the exact address, its type (read or write) and the CPU on which the fault occurred.
Then, it checks if the page fault has been injected by \gls{Moca} or if this is a legitimate page fault.
In the first case, \gls{Moca} \emph{fixes} it by setting the \texttt{PRESENT} flag on the Page Table Entry.
The hashmap entry indicating that the fault was triggered by \gls{Moca} should then be removed, but this would required a write lock, so we only mark the hashmap entry as \texttt{BAD}.
\texttt{BAD} entries are removed, if needed, when the monitoring thread, which holds a write lock on this hashmap, injects false page faults.
If a fix occurred in the \gls{Moca} handler, Linux silently aborts the page fault when it resumes its execution.
In the other case, it executes a normal page fault handling.
Each page fault increases an atomic clock that is used to timestamp the beginning and end of the chunks.
In this description, one can notice that a race might occur if the monitoring thread enables a false page fault between the end of our handler and the end of Linux page fault handler.
To avoid that, \gls{Moca} stores for each CPU the last address that faulted, and does not clear it.

%All default values for the parameters that can influence either the accuracy of the trace or the
%overhead of the tool (such as the number and size of chunks, wakeup intervals
%for the monitoring thread and the logging process \ldots) can be overridden by the
%user. Nevertheless, reasonable defaults have been defined from the experimental study
%detailed in section~\ref{sec:expe-param}.

\section{Tools Comparison}
\label{sec:Tools-Comp}

We compare \gls{Moca} and \gls{Tabarnac} to other existing memory analysis tools.
In a first time, we present their main differences in terms of portability and capabilities.
Then, we present two sequences of quantitative experiments, one that outlines the importance of the default parameters chosen for our \gls{Moca} and the other that compares the precision and performance of all the tools.

\subsection{Methodology}

Our main experiments were run on  machines from \gls{Grid5000} \texttt{Edel}
cluster (Intel machines).
As some state of the art tools can only run on \gls{AMD} machines, we also ran
    some of the experiments on
    \texttt{StRemi} machine from \gls{Grid5000} grenoble.
    These machines hardware specifications%
    \footnote{\gls{Grid5000} provides an online hardware description:\\
       \url{https://www.grid5000.fr/mediawiki/index.php/Grenoble:Hardware\#Edel}
       \\\url{https://www.grid5000.fr/mediawiki/index.php/Reims:Hardware\#Stremi}}
    are summarized in \tbl{hw-moca}.

\begin{table}[htb]
    \centering
    \begin{tabular}{lllllllllll}
        \toprule
        & \multicolumn{5}{c}{\textbf{Totals}}\\
        & Nodes & Threads & Vendor & Model & Memory \\
        \cmidrule(lr){2-6}
        \texttt{Edel}    & $2$ & $8$  & Intel & Xeon E5520      & \SI{24}{Gib} \\
        \texttt{StRemi} & $2$ & $24$ & AMD   & Opteron 6164 HE & \SI{48}{Gib} \\
        \midrule
        & \multicolumn{5}{c}{\textbf{Per node}}\\
        & Cores & Threads & Frequency & L3 Cache & Memory \\
        \cmidrule(lr){2-6}
        \texttt{Edel}   & $4$  & $4$   & \SI{2.27}{Ghz}& \SI{8}{Mib}  & \SI{12}{Gib} \\
        \texttt{StRemi} & $12$ & $12$  & \SI{1.70}{Ghz}& \SI{12}{Mib} & \SI{24}{Gib}\\
        \bottomrule
    \end{tabular}
    \caption{Hardware configuration of our evaluation system.}
    \label{tab:hw-moca}
\end{table}

\begin{table}[htb]
    \centering
    \begin{tabular}{lcccc}
        \toprule
         & \textbf{Moca} & \textbf{Tabarnac} & \textbf{Mitos} & \textbf{MemProf} \\
            \midrule
            \emph{Design} & & & &\\
            \midrule
            Mechanisms   & Page faults  & Inst* & PEBS + Inst* & IBS \\
            Architecture & \textbf{Any} & Intel (AMD) & Intel & AMD   \\
            \midrule
            \emph{Completness} & & & &\\
            \midrule
            Trace Granularity & \textbf{Address} & Page          & \textbf{Address} & \textbf{Address} \\
            Superset          & \textbf{Page} & \textbf{Page} & None             & None             \\
            \midrule
            \emph{Detail} & & & &\\
            \midrule
            Temporal data & \textbf{Yes} & No          & \textbf{Yes} & \textbf{Yes} \\
            CPU location  & \textbf{Yes} & No          & \textbf{Yes} & \textbf{Yes} \\
            Nature        & \textbf{Yes} &\textbf{Yes} & Yes**         & Yes**       \\
        \bottomrule
    \end{tabular}
    \caption[Comparison of different memory traces tools.]
    {Comparison of different memory traces tools.\\
        *Inst: Instrumentation.\\
        **Type (Read/Write) must be deduced from the instruction name.}
        \label{tab:tools-comp}
\end{table}


For each experiment, we deployed the same \emph{Debian} \emph{Jessie} environment running a \texttt{Linux 3.16.0-4} on a machine with hyper threading disabled.
We disabled address space randomization to make the comparison between different traces more practical.
As our two evaluation machines do not have the same hardware, we limited the number of threads used by \gls{OpenMP} to $8$, that is the largest number of hardware threads available on both machines.


We evaluate \gls{Moca} and \gls{Tabarnac} by comparing them to the following state of the art tools. The first one,
\gls{Mitos}, is the tracing tool from \gls{MemAxes}~\cite{Gimenez14Dissecting} and relies on \gls{Intel} \gls{PEBS} technology.
The third one, \gls{MemProf}~\cite{Lachaize12MemProf}, is designed to analyze \gls{NUMA} performance issues and relies on \gls{AMD} \gls{IBS}.
The main differences between these memory profiling tools are summarized in \tbl{tools-comp}.

\begin{table}[htb]
    \centering
    \begin{tabular}{p{3cm}ccl}
        \toprule
        Group & Name & Footprint & Description \\
        \midrule
        \multirow{4}{*}{Memory Intensive}
        & \IS & \SI{132}{Mib} & Integer Sort \\
        & \CG & \si{125}{Mib} & Conjugate Gradient \\
        & \MG & \si{508}{Mib}& Multi-grid \\
        & \FT & \si{398}{Mib}& Discrete 3D FFT \\
        \midrule
        \multirow{2}{*}{Unstructured}
        & \UA & \si{112}{Mib}& Unstructured Adaptive mesh \\
        & \DC & $1.46$Gib & Data Cube \\
        \midrule
        \multirow{3}{3cm}{Pseudo Applications (solvers)}
        & \BT & \si{120}{Mib}& Block Tri-diagonal \\
        & \SP & \si{122}{Mib}& Scalar Penta-diagonal \\
        & \LU & \si{118}{Mib}& Lower-Upper Gauss-Seidel \\
        \midrule
        CPU bound & \EP & \si{78}{Mib}& Embarrassingly parallel \\
        \bottomrule
    \end{tabular}
    \caption{Description of the \gls{NPB}.}
    %\\ *\emph{maximum memory used, measured with Valgrind}.}
    \label{tab:NPB}
\end{table}

In the following sections, all the tools are evaluated on each of the 10 \gls{NPB}~\cite{Jin1999}, which are presented in \tbl{NPB}, according to the information available on the NASA website\footnote{
    \url{http://www.nas.nasa.gov/publications/npb.html}}.
In this table, we included the footprint of each benchmark, that is the maximum memory used, as reported by Valgrind.

In each experiment, \gls{Moca} and \gls{Tabarnac} were run with their default parameters,
except for the experiment about the influence of \gls{Moca} parameters.
For \gls{Moca}, their default values are: a wakeup interval of \SI{0.5}{s} for the logging process and \SI{50}{ms} for the monitoring thread.

Each point in each plot is the average of at least $30$ executions.
Along with each point, the error bars represent the standard error.

We distribute\footnote{
    See our experiment repository:
    \href{https://github.com/dbeniamine/Moca_expe}{github.com/dbeniamine/Moca\_expe}
} all the files needed to reproduce our experiments at three different levels:
The first level contains the filtered results (csv files) from the experiments along with the \texttt{R-markdown} scripts that generated the plots presented in this article, making possible the reproduction of our statistic analysis.
The second consists of the full raw traces generated by our experiments along with the scripts used to extract the filtered traces (csv files from the previous level) and the scripts used at the previous level to perform the analysis.
Finally, at the most comprehensive level, we provide a git repository that includes our deployment environment, dependencies to all the tools and files required and instructions that explain how to reproduce the experiment with or without access to \gls{Grid5000}.


\subsubsection{Moca validation}
\label{sec:expe-param}

Before comparing \gls{Moca} to existing tools, we need to evaluate the impact of the wakeup intervals (logging daemon and monitoring thread) on the trace \emph{precision} and on the overhead.
To do so, we run the \IS benchmark instrumented by \gls{Moca} with a wakeup interval ranging from \SI{0.1}{s} to  \SI{0.9}{s} for the logging daemon and from \SI{20}{ms} to \SI{100}{ms} for the monitoring thread.
For each run, we measure \IS execution time and the number of accesses captured.
We have chosen \IS for this evaluation as it is one of the memory intensive out of the \gls{NPB} and quick experiments with other ones confirmed these results.
This experiment was run on a machine from the \texttt{Edel} cluster.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{moca/moca_param.pdf}
        \caption{Execution time.}
        \label{fig:param_time}
    \end{subfigure}
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{moca/moca_param_events.pdf}
        \caption{Number of captured events.}
        \label{fig:param_evts}
    \end{subfigure}
    \caption[Influence of Moca wakeup intervals.]{Influence of the wakeup intervals on \IS, class A.}
    \label{fig:param}
\end{figure}

We can see on the \fig{param_time} that the execution time increases when we reduce the monitoring wakeup interval.
At \SI{40}{ms} it seems to reach its worst level, thus we should keep it larger.
At \SI{50}{ms}, the default value we have chosen, the \fig{param_evts} shows that we obtain more than two thirds of the events captured at smaller intervals, which seems sufficient to us.
Regarding the logging interval, our experiments do not exhibit a clear trend.
Changing it seems to interfere with the system I/Os scheduler resulting in chaotic variations both in the execution time and the number of captured events.
The fact that variations in execution time result in matching variations in the number of captured events is due to the fixed length of monitoring intervals : the longer the execution, the more monitoring intervals there are and the more events the trace contains.
Overall these variations are not significant as all the confidence intervals intersect.
Finally we have chosen a logging interval of \SI{0.5}{s}, the median value, in order to avoid unnoticed effect caused by extremum values.

\subsubsection{Comparison with existing tools}

Preliminary experiments showed us that \gls{Mitos} capture by default way less distinct pages than \gls{Tabarnac} and \gls{Moca}.
Thus, we tried to change \gls{Mitos} sampling period in order to make it capture as many pages as possible, we name this version MitosTun.
Surprisingly, \gls{Mitos} behavior regarding this sampling period is not monotonous, we had to try many different periods to find the proper one.

The default \gls{MemProf} distribution did not work with our experimental setup.
With the help of their support team\footnote{
    see issue at \href{https://github.com/Memprof/scripts/issues/1}{github.com/Memprof/scripts/issues/1}
}, we managed to make it work by disabling the library used to retrieve data structures names.
For the same reason as in the case of \gls{Mitos}, our study includes two versions of \gls{MemProf}: the default version and MemProfTun for which we have increased the sampling rate to its maximum.

\DB{Expliquer MocaPin ancienne: version ou refaire une campagne d'expé ?}
Finally our evaluation also distinguishes \gls{Moca} (kernel module only) from
MocaPin, which also retrieve the data structure information using a Pin
instrumentation. We make this distinction to evaluate the impact of Pin on
\gls{Moca} performances.

We compare the different tools regarding two metrics, trace \emph{precision} and induced slowdown.
Regarding the trace \emph{precision}, the first experiment compares the tools using two criteria, the percentage of captured pages and the number of captured events.
We use \gls{Tabarnac} as a reference to compute the total number of pages accessed by the application because, by design, it traps all the memory accesses to compute the number performed in each page.
This metric is representative of the coverage of the memory space, that is the capacity of the tool to outline the whole memory area accessed by the application.
Regarding the number of captured events, we present the percentage relative to \gls{Moca}, as it is the tool that usually provides the more \emph{precise} traces.
We define one event as one timestamped access found in the trace file outputted by a tool.
According to this definition, \gls{Tabarnac} does not capture any event as it only keeps one counter per page and per thread without any temporal information.
Thus, \gls{Tabarnac} is excluded from this comparison.
The number of captured events is representative of the \emph{precision} of a monitoring tool, its capacity to keep track of all the evolutions of the access patterns during the course of the execution.
The idea is that, the more the tool captures events, the less it misses changes in the access patterns.

The second experiment compares the slowdown factor of the different tools.
All these experiments have been run on each of the \gls{NPB} on class A.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{moca/moca_pages_intel.pdf}
        \caption{Percentage of captured pages.}
        \label{fig:pages}
    \end{subfigure}
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{moca/moca_addr_intel.pdf}
        \caption{Percentages of events captured (compared to \gls{Moca}).}
        \label{fig:addr}
    \end{subfigure}
    \caption{Precision of the traces generated by each tool.}
    \label{fig:pages-addr}
\end{figure}

\fig{pages-addr} presents the results of the precision evaluation for the different tools.
The values used for \gls{Mitos}, MitosTun, \gls{Moca} and \gls{Tabarnac} result from runs on \texttt{Edel} machines, while \gls{MemProf} and MemProfTun values result from runs on \texttt{StRemi}.
We can see on \fig{pages} that \gls{Moca} captures almost as many pages as \gls{Tabarnac}.
Regarding their design they should capture as many pages.
Nevertheless, there is a slight bump in the number of pages used by applications monitored by \gls{Tabarnac} due to the Pin instrumentation.
Indeed, its JIT instrumentation recompiles the executable on the fly and changes the memory footprint (of the stack, mainly).
Thus, we can safely ignore these differences.

\gls{Mitos} usually collect less than \SI{12.5}{\%} of the pages, adding some fine tuning can almost double this number but it still misses most of the address space.
Regarding \gls{MemProf}, changing the default sampling rate does not seem to have any noticeable impact on the end result.
Both \gls{MemProf} and MemProfTun capture significantly more pages than \gls{Mitos} and MitosTun.
Nevertheless, for half of the studied applications it does not see more than \SI{50}{\%} of the addresses space.
Only for, \BT, \LU, \SP and \UA, \gls{MemProf} manages to capture around \SI{75}{\%} of the accessed pages.
This is explained by the fact that all these benchmarks are using uniformly most of their address space, and that many pages are frequently accessed.
This is coherent with the fact that \gls{MemProf} is solely based on instructions sampling and only sees the most accesses pages.

From \fig{addr} we can see that, as expected, for almost every benchmarks, \gls{Moca} collects significantly more events than the other tools.
 The only benchmark for which \gls{Moca} is not the more \emph{precise} tool is \EP which is an Embarrassingly Parallel application with very few memory accesses.
This outlines the fact that \gls{Moca} captures events in an uniform way, timed by the monitoring interval.
On the contrary, the other tools might capture more events in a few hotspots presents in the application but miss sparse accesses during the rest of the execution.
For almost every other benchmarks both \gls{Mitos} (with or without tunning) and \gls{MemProf} hardly reach \SI{10}{\%} of the accesses collected by \gls{Moca}, the only exception is \DC for which \gls{MemProf} captures from \SI{25}{\%} to \SI{50}{\%} of the accesses collected by \gls{Moca}.

These results prove that most existing tools can miss a considerable part of
the address-space while \gls{Moca} guarantee that it provides a superset of the accessed pages.
Furthermore they show that \gls{Moca} is the only existing tool able to provide a trace that is \emph{precise} enough to give an good overview of the memory use of an application.
In short, not only our tool provides a \emph{complete} trace at the granularity of the page but it is also significantly more \emph{precise} than the other existing tools.

\begin{figure}[htb]
    \centering
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{moca/moca_overhead_intel.pdf}
        \caption{Evaluation on \texttt{Edel} (Intel)}
        \label{fig:ovh-moca-Intel}
    \end{subfigure}
    \begin{subfigure}{.49\linewidth}
        \includegraphics[width=\linewidth]{moca/moca_overhead_amd.pdf}
        \caption{Evaluation on \texttt{StRemi} (AMD)}
        \label{fig:ovh-moca-AMD}
    \end{subfigure}
    \caption[Slowdown factor of each tool.]{Slowdown factor of each tool.
    Y-axis in log scale.}
    \label{fig:ovh-moca}
\end{figure}

\fig{ovh-moca} shows for each of the \gls{NPB}, the slowdown factor when instrumented by \gls{Moca} and the other existing tools on Intel (\fig{ovh-moca-Intel}) and AMD (\fig{ovh-moca-AMD}) Machines.
Notice that the Y-axis is in log scale.

From \fig{ovh-moca-Intel}, we can see that \gls{Mitos}, MitosTun overhead is almost negligible which is not the case for \gls{Moca} and \gls{Tabarnac}, this difference is explained by the results of the previous experiment, as these tools usually collects less than \SI{10}{\%} of the accesses collected by \gls{Moca} and miss a significant part of the address space.

We can classify the benchmarks into three groups: for \BT, \CG, \DC,  \EP, \LU, \SP and \UA, \gls{Moca} is significantly faster than \gls{Tabarnac}.
This set of benchmarks is interesting as it is made of varied application profiles as we can see in \tbl{NPB}.
Indeed, if \EP is mostly doing parallel computation with only a few number of memory accesses, \CG is described as memory intensive, \BT, \LU as well as \SP are linear algebra solvers with regular memory access patterns, and both \UA and \DC contain \emph{unstructured computation, parallel I/O and data movement}.
Furthermore, \DC has a considerable memory footprint as described in \tbl{NPB}.
The second group only contains memory intensive benchmarks (\FT and
\IS). For this group, \gls{Moca} is as good as \gls{Tabarnac} or a bit faster, probably
because the balance between computations and memory accesses hides the
overhead of the instrumentation.

For the last benchmark: \MG, \gls{Moca} is significantly slower than \gls{Tabarnac}.
By looking at our experiment logs, we found that \MG generates a lot of conflicts in the hash map used by \gls{Moca} to store false page faults.
This issue is caused by applications that perform a very large number of sparse accesses to a large working set.
This is not usual as parallel applications are often optimized to make memory accesses as local as possible in order to take advantage of all the levels of the memory hierarchy.
Thus, we consider this benchmark as a pathological case.
A solution could be to increase the size of this hash map, which is not always possible as memory space in the kernel is limited (and these experiments have been run with the largest hash map we could use).
Another easier solution would consist in working on a smaller instance of \MG and see if the trace is still useful.
Although the results are not presented here, we have run \gls{Moca} on \MG with a smaller size (W) and we have been able to confirm that the performance becomes comparable to \gls{Tabarnac} in this case.

\fig{ovh-moca-AMD} shows the results of the evaluation on the AMD machine
(\texttt{StRemi}). On this machine, \gls{Moca} overhead is quite similar to the one
obtained on \texttt{Edel}.
\gls{MemProf} exhibits a slowdown factor comparable to \gls{Mitos} while
providing traces a little more \emph{precise}. Nevertheless, they are still \emph{incomplete} and
way less \emph{precise} than \gls{Moca} traces. Obviously MemProfTun has the same
overhead as \gls{MemProf} as it capture the same amount of data.

\DB{MocaPin}
Finally, we can see, as expected, that adding one execution with a Pin instrumentation to retrieve data structures information (MocaPin) only adds a small overhead to the whole \gls{Moca} execution.
For several benchmarks this difference is so small that we cannot distinguish it from \gls{Moca} usual overhead.

%\subsection{Summary}
%\label{sec:expe-cncl}
\subsection{Results and discussion}

We have tested \gls{Moca} and \gls{Tabarnac} with various applications and using several parameters.
Our experiments, show that \gls{Moca} has a good behavior for a wide range of parameters and helped us defining their default values.
Our experiments also show that, with these parameters, \gls{Moca} provides significantly more precise traces than state of the art tools.
Of course, because of this increased precision, \gls{Moca} is slower than two of these tools, \gls{MemProf} and \gls{Mitos}.
Nevertheless, the comparison with \gls{Tabarnac} outlines the fact that, when a superset of the memory space is captured, \gls{Moca} efficiency is good.
Doing this using \gls{MemProf} and \gls{Mitos}, and provide the same guarantee, would require to sample all the memory instructions, which is not possible.
At the end of the day, \gls{Moca} is the only tool able to provide a detailed trace with temporal, spacial and sharing information while providing guarantees on the information lost during the sampling.


\section{Conclusions}

We addressed the issue of memory accesses collection for multithreaded applications.
This is a key challenge in high performance computing as memory is often a performance bottleneck.
Memory traces can be used at runtime to improve data locality or offline by developers to understand and improve the memory behavior of their applications and, therefore, their performances.
For online analysis the trace \emph{precision} is limited by the volume of data that can be analyzed in real time, but for offline usage, highly accurate traces can provides a better understanding of the application memory behavior.

\gls{Tabarnac}, our first attempt at collecting memory traces is designed specifically for \gls{NUMA} related issue.
It relies on a custom memory tracer based on the Pin dynamic binary instrumentation tool which records the number of memory reads and writes performed by all threads for each data structure.
The advantage of instrumentation is that it is the most accurate and portable way to generate memory traces.
Despite the overhead caused by the instrumentation, \gls{Tabarnac} is efficient enough to analyze even huge applications in a reasonable time.

We analyzed two parallel applications with \gls{Tabarnac}: \emph{Ondes3D}, a real life application that
simulates seismic waves, and \IS from the \gls{NPB} which is known for being memory intensive with a random memory access pattern.
For both applications, \gls{Tabarnac} helped us understand their performance issues.
Using this knowledge, we proposed simple code modifications to optimize the memory behavior resulting, for each application, in significant speedups compared to the original version (up to $60\%$ speedup).
Improvements were also substantially higher than those provided by automated tools.
Yet, \gls{Tabarnac} traces are not \emph{precise} as they only contains a global overview of the memory sharing patterns without temporal information.
Therefore they only allow to observe a limited number of memory related issues.

To address this challenge, we propose \gls{Moca} an efficient tool for the collection of \emph{precise}, \emph{complete} and \emph{detailed} memory traces.
While existing tools rely on \emph{incomplete} hardware sampling to provide such traces at an acceptable cost, \gls{Moca} provides a \emph{complete} trace, that contains all the accessed areas, at the granularity of the page.
Moreover, \gls{Moca} traces not only contain all the pages that are accessed during the execution, but also, for each trapped access, temporal, spatial and sharing information: accesses are timestamped and recorded along with their thread number, CPU number, and kind.
While \gls{Moca} works at the page granularity, it stores the exact address of each intercepted accesses.
Therefore, it also provides an \emph{incomplete} trace at the granularity of the byte, similar to traces collected by instructions sampling.
Furthermore, \gls{Moca} is also able to relate accesses to data structures of the application by combining this efficient trace collection system with an examination of the application binary.

Most state of the art tools are relying on hardware technologies such as \gls{Intel} \gls{PEBS} or \gls{AMD} \gls{IBS}, and embed vendor (or processor) dependent code making them hard to maintain and not portable.
On the contrary, \gls{Moca} is based on page faults interception as well as false page faults injection mechanisms and does not use any architecture dependent code.
It can work on any \gls{Linux} kernel from $3.0$ only by loading a module and without any kernel modification.

Several tools uses page faults interception to retrieve information about the memory use.
As information provided by only intercepting regular page faults is not always \emph{precise} enough, a few tools also inject false page faults on a regular basis to increase the trace \emph{precision}.
To our knowledge, all the existing tools relying on these mechanisms uses the collected data online and, thus, do not have to manage and store a large volume of data.
\gls{Moca} is the first tool able to generate and store \emph{complete} and \emph{precise} memory traces for offline analysis.

We evaluated \gls{Moca} and \gls{Tabarnac} by comparing them to two state of the art tools: \gls{Mitos} and \gls{MemProf} (both with their default parameters and with some fine tunning of our own).
For this comparison, we evaluated two criteria: the \emph{precision} of the trace and the runtime overhead.
We ran our evaluation on the \gls{NPB} which are representative of multiple kinds of applications from simple kernels to realistic ones.
Our evaluation has exposed the fact that the tools relying on hardware sampling miss a large part of the address space.
It has also shown that \gls{Moca} is able to provide both a \emph{complete} trace at the page granularity and a sampling at the byte granularity significantly more \emph{precise} than the other tools.
Generating comparable traces using \gls{MemProf} or \gls{Mitos} would require to sample more memory instructions than the hardware can.
Finally, \gls{Moca} overhead is more important than the overhead of sampling based tools but usually lower than the one induced by binary instrumentation.

Future work will focus on the visualization and exploitation of these memory traces which is another challenge mainly due to the volume of the collected data.

% vim: et si sta lbr  sw=4 ts=4 spelllang=en_us
