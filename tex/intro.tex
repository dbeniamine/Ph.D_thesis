%!TEX encoding=UTF-8 Unicode
\chapter{Introduction}

% De tout temps les homes
Scientists from all fields use computing to ease their calculations and run simulations to test their hypothesis.
These simulations are more and more complex and therefore requires always more computing power.
In a first time, computer vendors increased the this power by increasing the frequency of their \glspl{CPU}.
Still, this approach reached quickly several hard limits, therefore they started to build parallel processors.

% Hard limits
The first limit comes from the energy required to increase the frequency of a \gls{CPU}.
Indeed, according to \gls{Intel}, over-clocking a processors by \SI{20}{\%} only increase the performances by a factor $1.13$ but requires $1.73$ more energy.
At the opposite, using an identical processors with two cores instead with a frequency \SI{20}{\%} smaller provides $1.73$ times more performances for only $1.02$ times more energy.
The second hard limit is the speed of light: data have to travel from memory to the \gls{CPU} and cannot go faster than the speed of light.
While this limit can seem high, if we want to build a sequential machine able to process \SI{1}{TByte} of data per second, due to this limit it would require  to stick \SI{1}{TByte} of data on an area of \SI{0.3}{mm^2} which means $1$ bit occupies the size \SI{0.1}{nm}.

% Multi socket
While these parallel processors are theoretically more powerful than sequential ones, it is way more complex to use them efficiently and it is the responsibility of the developer to do so.
Moreover since a few years we are reaching yet another physical limitation.
While we are capable of reducing the size of transistors, hence increasing the number of transistors in a chip, more transistors means more heat, and it is not possible to dissipate efficiently heat in a few tens of nano meters.
As a results, vendors are know building machines with several sockets, each one embedding several cores.

% Gap CPU / memory => caches
At the same time, processors became significantly faster than memory, thus, \gls{CPU} embed small caches memory to limit the impact of this gap on performances.
To serve efficiently each cores of a \gls{CPU} these caches are organized hierarchically.
Furthermore, for the same reason, computers with several sockets have a \gls{NUMA} which means that each socket has a privileged access to a subpart of the memory.
Consequently, the memory access pattern of an application can significantly impact its performances.

% Need for perf analysis
In the end, writing an efficient program requires to consider the architecture of the computer that will run it, even if the program is sequential.
This task is extremely complex even for \gls{HPC} specialists.
As a result, any application which requires performances can benefit from performances analysis and optimization.

% Classic tool not good for memory related issue
The first step to optimize the performance of an application is to find the hotspots, which means the parts of code that are inefficient and understand their nature.
Only at this point it is possible to decide what part of code should be improved and how.
There are many tools designed to analyze the performances of an application, most of them relies on performance counters to collect a trace of the application.
Performance counters are \gls{CPU} register dedicated to performance analysis they enable efficient collection of performance data.
While these counters can be very useful, they consider the memory as a monolithic entity which is not the case on recent architecture.
As a result, tools based on performance counters can help find memory related performance issues, but they are not always able to identify the nature of the issue and they cannot show the pattern responsible for the bad performances.
Thus, specific tools should be used for memory performance analysis.

% Memory analysis is complex
Analyzing an application performances in regards of the memory raises two challenges: the first one is the collection of the trace itself.
This is a complex task as their is no hardware comparable to the performance counter specialized to trace memory accesses.
Furthermore, every instructions of a program triggers at least one memory accesses, thus, collecting every single memory access is not possible.
Additionally, due to the lack of tracing hardware, a memory collection tool might easily become invasive and significantly change the behavior of the analyzed application.
The second challenge is the presentation of the trace.
Indeed, memory traces are extremely complex as they are spread over five dimensions: time, address space, \gls{CPU} location, threads and access type.
Furthermore, some of these dimensions are not trivial to represent, for instance the address space can be virtual or physical and the \gls{CPU} location is organized hierarchically.
In the end, memory analysis tools have to extract pertinent data and present them in a comprehensive way.

% Perfect memory tool
An ideal memory analysis tool should be able to present the memory access patterns of a programm to its developper, including informatio about data sharing between threads and the location of these accesses on the machine architecture.
Futhermore, such tool should highlight inefficient patterns.

% Existing tools
Several tools were designed for memory performance analysis, however most of them addresses the trace collection challenge by doing an instruction sampling.
Instruction sampling is a hardware based technique that enable tracing every instructions at a certain frequency.
While this methods enables efficient tracing it skip most of the memory address space.
As a result, it is impossible to visualize memory patterns from the collected trace.

% Proposition
In this thesis we propose two tools to analyze the memory behavior of an application.
Our first tool, called \gls{Tabarnac}, collects global memory traces without temporal information and present an overview of the sharing patterns of the data structures between the threads of the execution.
The second one, called \gls{Moca}, collects generic, fine grained  memory traces with temporal information.
We provide two approach to visualize \gls{Moca} traces, the first one is based on \gls{Framesoc} an existing generic trace analysis framework, while the second one relies on a programmatic exploration.

% Experiments
Conducting experiments in computer science can be extremely simple, but doing it in a reproducible way requires more planning and methodology.
Performance analysis wheter it is for optimizing an application or evaluate a tool requires to do complete experimental campaigns.
In this thesis we, we take a particular attention at making our experiments as reproducible as possible.
To do so, we clearly describe our experimental methodology and distribute the files required to reproduce all the experiments presented.

\section{Contributions}

In this thesis we proposed two approach to analyze the memory behavior of an application.
Our first approach focuses on the global sharing behavior and is specfically designed for \gls{NUMA} machines.
The second one collects fine grained traces and propose a deeper analysis.
Furthermore we ran several experimental campaigns to evaluate these tools and analyze memory traces taking a particular care for reproducibility.
All the files required to reproduce all these experiments are publicly available online.

\subsection{Global overview of the sharing patterns}

We designed \gls{Tabarnac} to analyze the memory sharing patterns of applications running on \gls{NUMA} machines.
This tools relies on an existing, lightweight binary instrumentation, based on the \gls{Intel} \gls{Pin} library, which counts how much each thread of an application accesses each page.
We added to this library the capacity to retrieve contextual information to associate memory addresses to data structure (static or allocated).
Moreover we designed several comprehensive visualization of the collected traces.
Using these visualization we where able to identify some performance issues and improve the performances of a well known benchmark by \SI{20}{\%}.

These results were published on an article at \gls{VPA} 2015 a Super Computing workshop~\cite{Beniamine15TABARNAC}.
Furthermore \gls{Tabarnac} is distributed as a free software under the \gls{GPL} license: \url{https://github.com/dbeniamine/Tabarnac}.
This work is the result of a collaboration with M. Diener and P.O.A Navaux from the informatica team of the \gls{UFRGS}, Porto Alegre, Brazil, financed by CAMPUS France.

\subsection{Fine grain memory trace analysis}

\gls{Moca} is our main contribution.
This tools relies on a \gls{Linux} kernel module to collect efficiently fine grain memory traces.
This kernel module intercepts page faults and injects false page faults during the execution.
It handle memory traces in the kernel space and flush them to userspace periodically.
Moreover we ported our data structures tracking library out of \gls{Pin} for \gls{Moca}.
Additionally we ran an extensive experimental comparison of \gls{Moca} comparing it to \gls{Tabarnac} and two state of the art memory analysis tools.

This work is the subject of two Inria research reports~\cite{Beniamine15Memory,Beniamine16Moca} and has been submitted at \gls{CCGRID} 2017.
As the previous tool, \gls{Moca} is distributed under the \gls{GPL} license:\\
\url{https://github.com/dbeniamine/Moca}.

We proposed two different approaches to visualize \gls{Moca} traces.
The first one is based on an existing general trace management and analysis framework called \gls{Framesoc}.
More precisely, it relies on \gls{Ocelotl} a \gls{Framesoc} tool that aggregates similar parts of the trace and present a simplified overview highlighting anomalies.

To make the visualization more scalable and use advanced filtering and zooms, we explored several \gls{Moca} traces in a programmatic approach with \gls{R}.
This attempts are saved and versioned in a labbook publicly available at github: \url{https://github.com/dbeniamine/Moca_visualization}.

\section{Thesis organization}

The remaining of this thesis is organized as follow:
in \chap{perf} we presents a case study on the performance analysis of \gls{SOFA}, a physical simulation tool.
This chapter first introduces \gls{Sofa} and its specificities and highlight the need for performances analysis.
We then discuss the existing generic performance analysis tools and our experimental methodology.
It finally highlight the need for specific memory performance analysis tools.
In \chap{mem}, we introduce some specificities of recent memory architectures, usual memory performance issues and how to fix them.
Then we discuss the existing memory performance analysis tools, their limitations and what we would expect from an ideal tool.
After that we present \gls{Tabarnac}, our first contribution, in \chap{tabarnac}.
We discuss its design and usage, evaluate its overhead and finally present some performance optimization done with the knowledge obtained with \gls{Tabarnac}.
In \chap{moca}, we describe our main contribution, \gls{Moca}.
To do so we first explain the challenge raised by fine grain memory trace collection and the design of \gls{Moca}.
Then we provide an extensive experimental evaluation comparing \gls{Moca} to two state of the art memory analysis tools and \gls{Tabarnac}.
\chap{analyzing} discusses the visualization of \gls{Moca} traces.
We first introduce \gls{Framesoc} and \gls{Ocelotl} and the discuss the results obtained with these tools.
Then we propose a programmatic approach and show the visualization obtained with it.
Finally we draw our conclusions and present some perspectives of future work in \chap{cncl}
% vim: et si sta lbr  sw=4 ts=4 spelllang=en_us
