%!TEX encoding=UTF-8 Unicode
\chapter{Conclusions and perspectives}
\label{chap:cncl}

In this thesis, we have addressed the issue of memory performance analysis.
It has been motivated by the fact that \glspl{CPU} are more and more parallel and their memory and caches are organized hierarchically.
Therefore, writing efficient code requires to consider this architecture, and is complex even for \gls{HPC} specialists.

In \chap{perf}, we presented a case study on the performance analysis of \gls{SOFA}, a physical simulation tool.
This case study highlighted the fact that generic performance analysis tools can help finding memory related issues, but are not sufficient to clearly understand the nature of theses issues in order to fix them.
This is due to the fact most performance analysis tools focus on the \gls{CPU} point of view.
Indeed, they consider the memory as a monolithic entity, missing information on how the accesses are organized inside it.

This thesis present several experiments, for each of them, we used a well defined methodology described in \chap{perf}, in order to ease reproducibility.
All the files required to reproduce each step of each experiment presented in this thesis are available online.

Analyzing the memory behavior of an application raises two challenges: the first one is to collect a trace complete and precise enough to contain memory patterns.
This is challenging as there is no hardware designed specifically for memory analysis comparable to the performance counters for \glspl{CPU} traces.
The second challenge is to provide a comprehensive visualization of the memory traces which are spread over five dimensions: time, address space, threads, \gls{CPU} location and access types.
A few tools were designed to analyze performance from the memory point of view, yet they rely on instruction sampling, which is a hardware assisted mechanism that enable interception of some instruction at a defined frequency.
The limit of instruction sampling based tools is that they miss a significant part of the execution and therefore are not able to display memory patterns or to give a global overview of the memory sharing.
As explained in \chap{mem}, these patterns can have a significant impact on the performance.
Therefore we consider that the existing memory analysis tools are not sufficient.

\section{Contributions}

We proposed two different tools to address the challenge of memory performance analysis.
The first tool, called \gls{Tabarnac} and presented in \chap{tabarnac}, is based on an existing binary instrumentation, which relies on \gls{Pin}, an instrumentation library developed by \gls{Intel}.
We improved this instrumentation to add contextual information allowing to determine on which data structure the memory accesses occurred.
Furthermore we designed several comprehensive visualizations to interpret \gls{Tabarnac} traces.
Finally we evaluated the overhead of \gls{Tabarnac} and used the knowledge acquired thanks to this tools to improve the performance of two benchmarks, resulting on \SI{20}{\%} performance gain on a well studied benchmark.
This work was published at \gls{VPA} 2015 a Super Computing workshop~\cite{Beniamine15TABARNAC}, and is the result of a collaboration with M. Diener and P.O.A Navaux from the \gls{GPPD} of the \gls{UFRGS}, Porto Alegre, Brazil.
Moreover \gls{Tabarnac} is distributed as a free software under the \gls{GPL} license: \url{https://github.com/dbeniamine/Tabarnac}.
This provides sufficient traces to understand and improve the global sharing pattern of an application.
Nevertheless, more precise traces are required to understand temporal and complex patterns.

Our second tool, \gls{Moca}, which is presented in \chap{moca}, is an efficient fine grain memory trace collection system.
This tool relies on a \gls{Linux} kernel module that we implemented.
It collects memory accesses by intercepting page faults at the operating system level.
As page fault does not occurs frequently it also injects false page faults frequently to increase the number of intercepted accesses.
We ran an extensive experimental evaluation of \gls{Moca}, comparing it to two state of the art memory performance analysis tools and \gls{Tabarnac}.
We compared these tools in terms of overhead, trace precision, and completeness.
This work is the subject of two Inria research reports~\cite{Beniamine15Memory,Beniamine16Moca} and has been submitted at \gls{CCGRID} 2017.
As the previous tool, \gls{Moca} is distributed under the \gls{GPL} license: \url{https://github.com/dbeniamine/Moca}.

As \gls{Moca} traces are more complex than the one from \gls{Tabarnac}, we do not provide visualizations with the collection system.
Nevertheless, we proposed two different techniques to analyze \gls{Moca} traces, which are presented in \chap{analyzing}.
The first technique relies \gls{Framesoc} a generic trace management framework.
More precisely it uses one of \gls{Framesoc} tools called \gls{Ocelotl}.
This tool is designed to aggregate traces based on a model of the trace, highlighting anomalies and pattern changes.
The importer required to read \gls{Moca} traces in \gls{Framesoc} is published as free software:\\
\url{https://github.com/dbeniamine/framesoc\_importer\_moca}.\\
With this tool we were able to visualize several inefficient pattern on a test application.
However we encountered some scalability limits with this tool.
Consequently we proposed a second approach to analyze \gls{Moca} traces, based on a programmatic exploration of the trace using \gls{R}.
We analyzed several programs and were able to visualize memory patterns.
Our analysis are stored on a labbook publicly available online for reproducibility purpose:\\
\url{https://github.com/dbeniamine/Moca_visualization}.

After these analysis, it appears that \gls{Moca} traces are precise enough to identify temporal memory patterns.
Moreover they are sufficiently small to be analyzed.
Nevertheless, it seems that the sampling rate and the granularity of \gls{Moca} might be too high to detect clearly very fine grain patterns such as false sharing on a few lines of caches.


\section{Perspectives}

Our contextual library used in both \gls{Moca} and \gls{Tabarnac} is extremely useful to understand which data structure inefficient memory patterns occurred in.
However, this library could be improved by two means.

The first one would be to take into account the lifetime of data structures.
Indeed, our library does not handle data structures suppression and reallocation.
This could lead to erroneous interpretation in the analysis of complex applications that uses many temporary data structures.
Adding temporal information in this library is not trivial:
Indeed, we do not run \gls{Moca} and the library at the same time, to avoid tracing memory accesses done inside the library.
Therefore the execution time of both runs are different and we would have to synchronize them after tracing.
This could be done by generating the call tree of the application and using it as a temporal indicator.
Furthermore, retrieving the mapping addresses to data structure will be more complex with this temporal information.

A second improvement that could be done to this library would be to identify complex data structures such as trees and lists.
We might be able to do so by looking at the addresses accessed right after and before allocating a data structure.
Nevertheless, this approach seems heuristic and requires to keep a huge amount of data online.
Another approach could rely on the developer knowledge and provide some callbacks to annotate allocations and post process them after the trace collection.

While \gls{Moca} traces enables visualization of memory patterns, it sometimes is hard to associate these patterns with some code a posteriori.
At this point we could use the developers knowledge to annotate their code before tracing it to highlight the data structures and parts of code that seems inefficient to them and guide the analysis.
However, as we saw in \chap{perf}, the developers knowledge can help the analysis but they might miss some hotspots.
Therefore, this knowledge should not be used to filtrate traces during the collection step, but to guide the exploration and interpretation during the analysis step.

\gls{Moca} is not able to detect extremely fine grain patterns such as false sharing on a few lines of caches.
However, the pages where such pattern occurs while appears as hotspots in \gls{Moca} traces.
Thus, it would be interesting to build an extremely fine grain collection traces that focuses on small parts of the execution, identified by a first analysis, to visualize these patterns.

Finally it would be interesting to use memory traces to understand proprietary code.
More specifically, it is sometimes hard to understand the performance of some kernels of the \gls{MKL} as its code is kept secret.
Comparing the memory patterns of the kernels from this library to equivalent free kernels might help to understand the differences of performance and to improve those free kernels.

A longer term perspective would be to build a tool similar to \gls{Moca} for recent memory oriented co-processors architectures, such as the \gls{Intel} Xeon Phi, or for \glspl{GPU}.
This would require to identify a mechanism that can be used to collect memory traces which is far from being trivial as we have far less control on these architectures than on general purpose \glspl{CPU}.
% vim: et si sta lbr  sw=4 ts=4 spelllang=en_us
