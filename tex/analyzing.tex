%!TEX encoding=UTF-8 Unicode
\chapter{Analyzing Fine Grained Memory Traces}
\label{chap:analyzing}

\gls{Tabarnac} traces contain two parts: informations about the data structures and the actual trace.
For small applications with a limited number of data structures, it is relatively easy to present the first kind of information.
The actual trace is spread over three dimensions: threads, pages and type of accesses, however, this last one can only take two values (read or write).
Finding a meaningful and comprehensive representation for such data is slightly more complex but it is still doable.
\gls{Moca} traces are way more generic.
Indeed, they contain the same meta data and the actual trace also provides information about time and \gls{CPU} location.
Therefore, these traces are spread over five dimensions: time, addresses, type of access, thread and \gls{CPU} location.
Furthermore some of these dimensions can be seen from several point of view, for instance we can look either at the physical or virtual address space.
As we are not used to visualize things in more than three dimensions, to analyze these traces, we must provide the user with a way to navigate through different representations.
Additionally, we need to help the user identify and focus on the important parts.

The contribution presented in this chapter consists in two different methods to analyze \gls{Moca} traces:
\begin{itemize}
    \item The first method relies on \gls{Framesoc}~\cite{Pagano14frameSoC}, an existing generic trace management tool, and more specifically one plugin called \gls{Ocelotl}~\cite{Dosimont14Ocelotl} that provide aggregated views of a trace.\\
        We have implemented an importer to analyze \gls{Moca} traces in \gls{Framesoc} that is distributed on Github under GPL License:\\
        \url{https://github.com/dbeniamine/framesoc\_importer\_moca}.\\
        The proposed visualizations are presented in a Research Report~\cite{Beniamine15Memory}.
    \item The second method relies on \gls{R}, it is an ongoing work, publicly available online at:
        \url{https://github.com/dbeniamine/Moca\_visualization}
\end{itemize}

This chapter is organized as follows: first we present our analysis of \gls{Moca} traces with \gls{Framesoc} and \gls{Ocelotl} with an example and discuss the limits of this method in \sect{visu-first}.
Then we propose a second, more flexible approach based on \gls{R} in \sect{visu-second}.
Finally we present some perspective of improvement of these analysis and our conclusions in \sect{visu-cncl}.


\section{Interactive visualization of aggregated traces}
\label{sec:visu-first}

As \gls{Moca} traces are spread over five dimensions and as the address space of an application can be quite large, we need a way to navigate easily in the trace and highlight interesting parts.
Consequently, we are looking for a tool that is able to run high level analysis with for instance the ability to spot anomalies.
While several generic trace manager tools such as \gls{HPCToolkit}~\cite{Adhianto10HPCTOOLKIT} are able to import generic traces, we decided to use \gls{Framesoc}~\cite{Pagano14frameSoC}.
This decision was mainly motivated by one of \gls{Framesoc} visualization tool, \gls{Ocelotl}~\cite{Dosimont14Ocelotl} that is designed specifically to aggregate similar parts of a trace and identify anomalies.

\subsection{FrameSoc and Ocelotl}

\gls{Framesoc} is a generic trace management infrastructure, it provides importers to read traces from many different format.
From its point of view a trace consists on five sets:
\begin{enumerate}
    \item Some meta data about the trace, such as the name of the trace, the application traced, the number of \glspl{CPU} used, the \gls{OS} and so on\ldots
    \item A set of \emph{Event Producers}: which are entities able to produce some \emph{Events}.
        For classic performance traces the Event producers are the \glspl{CPU}, threads or processes.
    \item A set of \emph{Events Types} used to classify the possible events.
        \gls{MPI} function calls and system calls are two usual event types.
    \item A set of \emph{Events}, \emph{Variables} and \emph{States} that form the actual trace.
        For instance in a classic trace, a call to a call to \texttt{MPI\_Send} could be an event, and a \gls{CPU} could be in \emph{idle} state after a call to \texttt{MPI\_Receive}.
        Variables are used to represent values that evolves as the time passes.
    \item A set of \emph{Links} that can be used to represent causality between events, variables and states.
\end{enumerate}

To analyze a trace from an unknown format in \gls{Framesoc}, we need to write an importer which is a relatively simple task.
Indeed \gls{Framesoc} is implemented as an Eclipse plugin, consequently an importer is a small piece of java code that read a trace file, create the sets described above and store them in a database, using \gls{Framesoc} \gls{API}.
The main challenge in the writing of an importer is to figure out how to represent the trace in \gls{Framesoc} internal model.

\gls{Framesoc} provides several functionalities to explore a trace such as filtering events by type, name, focusing on a time frame.
Additionally it has a multi view representation which means that several views of the trace can be opened at the same time and synchronized.
For instance a user can start inspecting a trace with a Gantt chart, focus on a small part and then look at a pie chart of the event distribution in this subset of the trace.
\gls{Framesoc} is optimized to make such analysis as smooth as possible.

\gls{Ocelotl}~\cite{Dosimont14Ocelotl} is an analysis tool for \gls{Framesoc}.
This tool is particularly interesting for us as it provides an aggregated overview of a trace.
The idea behind \gls{Ocelotl} is that a trace with too many entities (events or event producers) is not understandable, consequently, it should be analyzed with a \emph{systemic approach}.
This means considering the whole trace as a system and finding a macroscopic representation of that system that contains an amount of information understandable by a human.
To do so, it uses an aggregation methodology proposed by Lamarache-Perrin~\cite{Lamarche_Perrin14Agregation} and adapted for trace analysis.
This methodology cuts the trace into small slices over the two dimensions: time and space (event producers).
Then it considers each possible partition, benefiting from the structure enforced on time and space to reduce the number of possibilities.
For instance, merging two slices that are not continuous over time is not allowed as it would not be meaningful.
In addition, it uses a parameter $p<[0,1]$ that controls the trade-off between information loss and data reduction and find the optimal partition for this parameters.
Once the first visualization is generated, \gls{Ocelotl} provide the ability to explore the trace (zoom, use \gls{Framesoc} filters \ldots) and change the $p$ parameter.
The usual workflow with \gls{Ocelotl} is starting with a high $p$, where the trace is mostly aggregated, zoom on anomalies or interesting parts and decreasing $p$ to understand more precisely what phenomena we are observing.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{ocelotl/overview.png}
    \caption{Screenshot of Ocelotl.}
    \label{fig:ocelotl-overview}
\end{figure}

\fig{ocelotl-overview} is a screenshot of \gls{Ocelotl}, showing on the main pane an overview of an example trace, aggregated over time and space (memory addresses).
The X-axis represents time and the Y-axis represent the memory space, we can see on the left that the Y-axis is organized hierarchically.
This hierarchy is used to reduce the number of possible aggregations, indeed, for one level of the hierarchy, \gls{Ocelotl} can only merges two event producers if they have the same parent.
Without any a priory knowledge of the trace application, we can distinguish three phases on this visualization: a short initialization (blue column at the beginning), the main execution with some pattern change around the two third of the execution.
The top right pane shows a summary of the trace aggregate only over the time.
On this summary, the initialization is a bit less visible.
Finally the bottom right pane shows a comprehensive visualization of the information versus complexity gain depending on the value of $p$.
The red curves show the information gain and the green one the complexity gain.
The current value of $p$ is showed by a blue vertical line, and displayed in a text block under the curve.
We can set the $p$ parameter either by clicking the curve or by entering the requested value inside the text block.
At this point the user could zoom in a subpart of the trace by selecting it, or change the parameter $p$ to disaggregate the visualization.

\subsection{Trace Description}

As explained earlier, \gls{Moca} traces are spread on five dimensions while \gls{Framesoc} is designed for two dimensional traces (time and event producers).
Nevertheless we can use the \emph{event types} of \gls{Framesoc} to represent some of the missing dimensions.
To provide different visualization of the same trace, our importer produces four different \gls{Framesoc} traces with different event types.
For all the traces, the event producers represent the memory addresses, but the two first are based on virtual addresses while the two others physical addresses.

The more event producer there are, the more partitions \gls{Ocelotl} must consider to compute the aggregation.
Yet, \gls{Ocelotl} uses the structure of the event producer hierarchy to reduce the number of allowed partitions, indeed it can only merge event producers that have the same parent.
Consequently we can counterbalance the huge number of event producers by creating an artificial hierarchy in the memory.
We can build a meaningful hierarchy that also adds some semantic to the trace: to do so we create a virtual \emph{Memory Root} event producer that is the parent of all the event producers.
Then, the second level of event producers is composed of the stacks and data structures.
All the addresses that are not in these set, are merged if they are contiguous, creating chunks of continuous addresses which are also second level event producers.
Then, each subsequent level is obtained by splitting the previous one on two or three parts, until we reach at the page level.
The pages are the leaves of this artificial memory hierarchy.
We could divide the pages in cache lines and keep going until the address granularity, but this would generate way more event producer that what \gls{Ocelotl} is able to handle.

For both physical and virtual addressing, our importer creates two different traces.
In the first type of trace, the events and spread on four event types: \texttt{private\_read}, \texttt{private\_write}, \texttt{shared\_read}, \texttt{shared\_write}.
For the second trace, the event type represent the  thread responsible of the access.
As a result we have for both physical and virtual addresses, we have two views one representing the usage of the memory by the threads and one global view presenting the sharing patterns and memory access type.

Each access is represented by a variable, whose value is the number of threads involved in the access.
Finally, the \gls{CPU} on which the access occurred is stored as an event parameter.

\subsection{Sharing detection}

\begin{figure}[htb]
    \centering
    \input{tikz/sharing-detection}
    \caption{Sharing detection on Moca traces.}
    \label{fig:sharing-detection}
\end{figure}

\gls{Moca} does not compute sharing only but the traces contains enough information to detect shared accesses.
Indeed in \gls{Moca} traces each access is timestamped with the begin and end of the chunk to which it belongs, which means that an access can be seen as a time interval during which a thread is using a memory page.
We do the sharing detection at the page level as \gls{Moca} traces are complete at the page granularity.
Consequently, we consider that a sharing occurs when two threads accesses the same page during and intersecting time interval.
To compute this sharing, we retrieve the list of accesses for each page.
Then we transform the cut the time interval each time a thread start or stop using a page and mark each access with the number of threads involved in the sharing.
\fig{sharing-detection} shows this transformation.

\subsection{Example}

To illustrate these visualizations we implemented an extremely naive parallel matrix multiplication.
In this example, a first thread does the whole initialization, then create four threads that will do the actual computations.
Furthermore, we split the work by cutting the result matrix in four parts, resulting in the distribution of the data structures presented in \fig{mat-mult-par}.

\begin{figure}[htb]
    \centering
    \input{tikz/mat-mult-par.tex}
    \caption{Naive parallel matrix multiplication}
    \label{fig:mat-mult-par}
\end{figure}

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{ocelotl/TaskView.png}
    \caption{By thread view of the memory usage of a naive parallel matrix multiplication.}
    \label{fig:ocelotl-th0}
\end{figure}

\fig{ocelotl-th0} is a screenshot of \gls{Ocelotl} by thread visualization of \gls{Moca}.
We can see the hierarchy on the Y-axis, starting with the memory root, then three data structures.
The X-axis represent temporal evolution.
%For more readability of the trace, we have set one color per thread independently from the type of access, thread zero is blue, one is green, two read, three orange and four violet.

From this view, we see clearly that blue accesses occurs only during the initialization phase except for a small data structure on the bottom of the figure.
Therefore we can see that the thread~$0$ is the master thread doing the initialization.
Moreover, the master thread also access to some private data (the small structures in the bottom).
Among these data, we can find a pid array used to wait the end of the slave threads.
We can confirm that by filtering the accesses to show only the accesses done by thread~$0$.
Or by zooming on the initialization phase.

During the rest of the execution, two data structures are accessed diagonally over the time, which means linearly.
Furthermore, the colors confirms that two threads are sharing each series of accesses.
The data structure in the middle is intensively accessed by every threads, as a result all the accesses are aggregated.

It seems that, at the two third of the execution, we can see a change of colors in the middle data structure.
Additionally, it seems that at the same time the violet thread has completed his work and does not access the memory anymore.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{ocelotl/TaskView-zoom-init.png}
    \caption{By thread view of the memory usage of a naive parallel matrix multiplication,
    initialization.}
    \label{fig:ocelotl-th1}
\end{figure}

Now let's zoom on the initialization step.
The result is shown in \fig{ocelotl-th1}.
We can see that, during the initialization phase, only the master thread is working.
We can identify a three diagonal patterns happening at the same time, it correspond to the matrix initialization.
The private data structures in the bottom also appears during the initialization.
Finally, we see that as soon as the thread~$0$ has finished to initialize the data structure, the other four threads start working.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{ocelotl/Sharing.png}
    \caption{Sharing view of the memory usage of a naive parallel matrix multiplication.}
    \label{fig:ocelotl-carto0}
\end{figure}

In the previous view there were four access type per threads (private / shared, reads / writes) which means $20$ different access types.
To make the trace more readable, we had to reduce the number of colors and stop distinguishing private access from shared and reads from writes.
The global view that is designed to highlight sharing only provides for event types independently from the number of threads.
Therefore, it is easier to identify sharing patterns with this view.
\fig{ocelotl-carto0} shows this visualization of our example traces.
We can see that the trace looks like the previous one except that the order of the data structures is different.
Blue accesses are privates and reds are shared.
Dark colors are for writes while light ones means reads.
From this view, we can see that most accesses seems to be reads and except for the matrix B (on the bottom) they are all private.
Still the visualization is aggregated, at this point it is interesting to zoom in the middle of the execution and desegregate the trace as much as possible.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{ocelotl/Sharing-zoom.png}
    \caption{Sharing view of the memory usage of a naive parallel matrix multiplication, computing phase.}
    \label{fig:ocelotl-Carto-zoom}
\end{figure}

By focusing on the middle of the execution and setting $p$ to zero, we obtain the \fig{ocelotl-Carto-zoom}.
It is important to note that the trace is still aggregate due to the microscopic model of the trace.
This aggregation explains the fact that we still see small, regular, blocks of accesses.
We cannot identify a clear pattern on the bottom matrix, however, we can see a few private (blue) accesses appearing from time to time in this data structure.
The access on this matrix seem dense and not designed to fit in a cache.
This density of accesses is coherent with the behavior expected.
Indeed the matrix by is accessed column first by all the threads.
Due to the representation of 2D matrices in \texttt{C}, each access of each thread on B is separated from $sz$ doubles.
Hence \gls{Ocelotl} groups almost everything in a huge chunks of access on all the matrices.
We can also see in this figure that shared (orange) accesses appears regularly on the two other data structures which is also coherent with the expected behavior.

\subsection{Discussion}

In summary, \gls{Ocelotl} enabled visualizing \gls{Moca} traces and helped identifying inefficient patterns on a test application.
However even for this extremely simple benchmark we started to see some scalability issues.
The first limit comes from the fact that \gls{Framesoc} is designed for a small number of event producers.
Indeed \gls{Framesoc} event producers usually represents threads, \glspl{CPU} or nodes of a distributed system with at best a few thousands of them.
At the opposite, our small example we already had $20000$ event producers for only \SI{78}{Mb} of memory usage, a trace using \SI{1}{Gb} would require more than $250000$ event producers.
We can mitigate the impact of the number of event producers on \gls{Ocelotl} by organizing them in an artificial hierarchy but this only reduces the computation time of \gls{Ocelotl}.
Filtrating the trace based on the event producers is extremely slow with such traces in \gls{Framesoc}.
The second issue comes comes the fact that we had to create several \gls{Framesoc} traces to represent all the information contained in \gls{Moca} traces.
As a result, changing analysis point of view means changing the trace, hence loosing all filtration already done and all caches that speeds \gls{Ocelotl} up.
Therefore it is a process extremely slow that breaks the analysis workflow.
While it would have been technically possible to merge the by thread view and the sharing view by creating complex event types holding information about access type, sharing and the thread responsible for it, this would result on a huge amount of event types.
Such a trace would results in two issues: first the microscopic description of the trace would be more complex which might \gls{Ocelotl} down,\DB{je suis pas sûr là \ldots}
and second it would make filtering by type extremely painful.
Indeed there is no way to do filtering using regular expression or any programmatic way in \gls{Framesoc}, thus, on a huge trace the user would have to do tens or hundreds or clics and might do some errors to switch from point of view.
Finally, with these traces it is not possible to have information about the data structure (their size and number of acesses), to do so we would have to create yet another trace during the importation.

To conclude, visualizing our traces with \gls{Ocelotl} proved that memory traces are helpful to identify performance issues.
Nevertheless, we identify several scalability issues in our analysis workflow due to the fact that generic trace analysis tools are not designed for the specificities of memory traces.
Consequently, a more flexible approach that ease switching from point of view and filtering would be more efficient to analyze our traces.

\section{Programmatic exploration}
\label{sec:visu-second}

The main drawback of using a generic visualization tool for analyzing \gls{Moca} traces come from the difficulty to switch the perspective from which we visualize the data.
More precisely, this limitation comes from the static representation of traces as a two dimensional entities used in most tools.
This is problematic for \gls{Moca} traces because not only they are spread over five dimensions, but these dimensions are related to each other.
Indeed, the placement of threads on the \glspl{CPU} is not necessarily fixed but it matters and can impact the performances.
Furthermore, this placement must be analyzed in relation to the placement of memory pages on the physical memory and on the underlying hierarchy.
As a result, projecting such traces on two dimension is complex and different projections should be analyzed and correlated to understand the memory behavior of an application.
Hence, a more programmatic approach may enable the analyst to work closer to the data and ease this point of view switch.

In \gls{R}, data are usually stored in huge dataframes, each row of a dataframe represent one observation and each column represent one dimension of this observation.
Consequently, in \gls{R}, changing the analysis point of view for a set of data only means looking at another column of the dataframe which is trivial.
While this representation has a significant memory footprint, \gls{R} is designed and optimized to do such analysis and to correlated different dimensions of a set of observation.
For these reason, we analyzed several traces with \gls{R}.
For more reproducibility, we store the evolution of our work in an \gls{Org-mode} labbook, as described in~\cite[Chapter~4, p~54]{Stanisic15Reproducible}, and available online at:\\
\url{https://github.com/dbeniamine/Moca\_visualization}.

While this approach is extremely flexible, it is not user friendly.
Indeed it requires to know how to write efficient \gls{R} code, how to use \gls{Org-mode} and Emacs and to read the labbook before doing an analysis.
Anyway, after a few analysis we obtained a basic procedure to analyze traces (parsing, transforming data, showing some generic visualization) from which we can adapt each step to the trace.
For instance we might want to ignore some parts of the trace very soon to focus on some data structures, or after analyzing one plot we might think of another representation of data that might be meaningful in this case.

\subsection{Design}

Our analysis always starts with a classical pipeline that we can easily adapt to the specificities of the analyzed trace:
\begin{enumerate}
    \item Parsing: reading \gls{Moca} traces (to which we have applied the sharing detection written for \gls{Framesoc} and depicted in \fig{sharing-detection})
        and storing them in \gls{R} dataframes.
        At the end of this step, we have two dataframes, the main one contains all the accesses, and the other one the list of data structures.
    \item Creating simplified data frames: At this point, the main dataframe contains a set of accesses where shared access appears one time for each thread involved in the sharing as described in \fig{sharing-detection}.
        We can aggregate all theses accesses, reducing the size of the main dataframe.
    \item Retrieving the mapping between structures and pages: this step is the most costly one, but can be speed it up by several means:
        \begin{itemize}
            \item At the end of the parsing step, we can reduce the interesting address space, usually we take the minimum and maximum addresses that are inside a data structure and filter out all the asses that are not in this interval.
            \item As there are significantly less data structures than memory addresses, we can do the mapping by applying on the data frame representing the structures, a function that returns a vector with one entry per line of the main data frame.
                When this function is applied, each data structures adds it names to the addresses that belongs to it.
                In the end we just have to add this vector as a column of the main data frame.
        \end{itemize}
    \item First set of predefined plots: Finally we can present some predefined  plots, the three first are inspired from \gls{Tabarnac} ones and show the size of data structures, the number of accesses, and amount of sharing.
    \item  Filtering: at this step we can easily identify data structures that or rarely used and might not have a significant impact on the application performances, we filter these data structures out to focus on the most important ones.
    \item Second set of predefined plots: for all the data structures that are left we visualize the memory accesses over the time depending on their type.
        For these plot, the color represent either the number of accesses or the number of threads involved in the access.
\end{enumerate}
At any step of the pipeline, it is possible to do more filtering using our knowledge of the analyzed application to speed the process up.
Once the predefined plots or obtained, we can easily navigate in them using \gls{R} selection operators to do complex filtering or zoom on a part of the trace.
Moreover it is possible to design any other visualization that might be interesting.

\subsection{Example of visualization}

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{labbook/intensity_Rw_dgetrf}
    \caption{Visualization of the memory access of the dgetrf kernel from ffplas-ffpack.}
    \label{fig:dgetrf-intensity}
\end{figure}

We illustrate our visualization with the \emph{dgetrf} kernel from the fflas-ffpack~\cite{group16FFLASFFPACK} compiled against the OpenBlas~\cite{Chothia16OpenBlas}.
This trace was collected on a machine from the Edel cluster which hardware was presented in \tbl{hw-moca}.

\fig{dgetrf-intensity} shows for each data structure\footnote{
    A few, almost unused, data structures have been filtered out to make the image more readable.}
    the number of accesses per page over the time.
Furthermore we differentiate four types of access: \texttt{PrivateRead}, \texttt{PrivateWrites}, \texttt{SharedRead} and \texttt{SharedWrites}.

For each structures, some accesses seemed to appear private and shared at the same time which is not possible.
Nevertheless, by zooming on a small part of the execution were able to confirm that those access are interleaved and never of both types at the same time.
This means that several threads are working on data very close and often do actually share some pages.

From this visualization we can see that two of the stacks (1252 and 1250) are always used privately.
Furthermore the data structure malloc\#5 seems to be used mostly privately and only very rarely read in a shared way.
These three structures seems also to be accessed mostly linearly, hence they should not be subject to memory optimization.

\lstinputlisting[caption={R code to focus on interesting data structures.}, label=lst:R-zoom,float=htb]{code/zoom.R}

At this point, it is interesting to focus on these three data structures and ignore the others, we can do this with the simple line of code displayed in \lstr{R-zoom}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{labbook/intensity_RW_dgetrf_zoom}
    \caption{Visualization of the memory access of the dgetrf kernel from ffplas-ffpack, zoom on the three interesting data structures.}
    \label{fig:dgetrf-share-zoom}
\end{figure}

We can see in \fig{dgetrf-share-zoom} that the sharing patterns are very similar to the access patterns.
The three other data structures present different and interesting memory access patterns.
First the malloc\#1 structure is very small and accessed intensively in a shared way, during all the execution and always on the same page.
We can presume that this data structure contains information about the threads status that must be updated quite often, maybe it is used for thread scheduling.
Second the stack 1256 is only used during the first third of the execution and written only at the beginning and in parallel.
For a generic data structure, this parallel initialization could probably have been designed to distribute first touch on the \gls{NUMA} nodes of the machine, still on a stack it seems quite unusual.
Last but not least, a small part of the main stack is accessed in read and write mode and in a shared way during all the execution.
This pattern means that threads are probably organized in a master / slave way, where the master thread allocates data in its stack (not a dynamic allocation).
This might be problematic on \gls{NUMA} machines as the stack is statically allocated and thus cannot be allocated explicitly on some node.
It would be interesting to zoom on the beginning of the execution to check if the initialization of this part of the stack is correctly spread around the thread or not.
If not, Linux will allocate each page on the memory bank of the master thread independently of the re partition of the data between the threads.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{labbook/intensity_Share_dgetrf_zoom-init}
    \caption{Visualization of the sharing patterns of the dgetrf kernel from ffplas-ffpack, zoom on the initialization of \texttt{stack:1256}.}
    \label{fig:dgetrf-share-zoom-init}
\end{figure}

\fig{dgetrf-share-zoom-init} shows the memory accesses occurring inside \texttt{stack:1256} during the first par of the execution.
The color indicates the number of threads involved in the memory access.
The first thing we can notice in this figure is that the data structure seems to be read before being written.
When a page that is not mapped to the memory is read before writing it, \gls{Linux} does not map it but read a page full of zeroes, consequently this behavior should not impact the first touch.
Then it seems that the first writes are both private and shared.
As a memory access cannot be both shared an private, that means these accesses occurs in parallel and some parts or accessed by two or three threads at a time while some others stays private.
We can confirm this behavior by zooming even more in the initialization.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{labbook/intensity_Share_dgetrf_zoom-init1}
    \caption{Visualization of the sharing patterns of the dgetrf kernel from ffplas-ffpack, zoom on a part of the initialization of \texttt{stack:1256}.}
    \label{fig:dgetrf-share-zoom-init1}
\end{figure}

By zooming even more, we obtain \fig{dgetrf-share-zoom-init1} which shows that access are indeed not shared and private at the same time.
Furthermore it confirms that the data in this stack are read before being written.

After discussing these results with some of the developers of the fflas-ffpack, it appears that the observed patterns can be due to the OpenBlas library and might be complex to improve.
Yet an interesting thing to do would be to compare these traces, with the trace of the same kernel but compiled against the \gls{MKL}.
Indeed, there are some performance differences between the two library that are hard to explain with traditional profiling tools as the \gls{MKL} code is proprietary.
Therefore, memory traces might help understanding the underlying algorithms.

In the end, this approach ease the exploration of \gls{Moca} traces, provided that we know a minimum of \gls{R} code and that we read our labbook.
This is more complicated than using \gls{Framesoc} and \gls{Ocelotl}.
Additionally, we had some troubles to analyze some traces from Lulesh \gls{OpenMP} and \gls{SOFA}.
Indeed these applications generates thousands of call to the malloc functions (hundreds of thousands for Lulesh).
Hence, retrieving the mapping page to data structure was extremely slow or nearly impossible without merging some data structures.
In the end it appears that we need to add a priori knowledge of the developers in the parsing step to filter out uninteresting data.

\section{Discussions}
\label{sec:visu-cncl}

Visualizing \gls{Moca} traces is a complex task.
Indeed these traces are spread over five dimensions: time, addresses (virtual or physical), threads, \gls{CPU} location and access type.
Furthermore, the address space is quite large and we are mostly interested in some specific patterns.
Therefore, we first used \gls{Ocelotl}, a part of \gls{Framesoc} infrastructure, to analyze these traces.
This tool is designed to aggregate traces in a meaningful way, trying to provide a good trade-off between information lost and data reduction.
Importing \gls{Moca} traces inside \gls{Framesoc} is interesting as it provides easy filtering and zoom on the traces.
Still, \gls{Framesoc} considers that a trace has two dimensions: time and event producers, it is hard to represent the complexity of \gls{Moca} traces in it.
\gls{Framesoc} event types could be used to represent this complexity.
In \gls{Ocelotl} event types are represented as a color, if the event types represent several dimensions, it is impossible to interpret the colors of a visualization.
Consequently, if a \gls{Framesoc} trace contains all the information, we must do some filtering by event types to be able to interpret it.
In \gls{Framesoc}, the only way to filter a trace by event type is to select individually some types by clicking on them.
As a result such a trace would not be usable and it is simpler to generate several distinct \gls{Framesoc} traces while importing one \gls{Moca} trace.
The main drawback of this workaround is that switching traces inside \gls{Framesoc} means loosing all zooms and filters along with the caches and the results of the aggregated views computed by \gls{Ocelotl}.
In the end this approach enable the visualization of small traces, yet the cost of changing the perspective is too high and makes the interaction too slow to be usable.

Our second approach to analyze these trace was more programmatic, we used \gls{R} and saved all our attempts in a labbook.
While this is less user friendly, \gls{R} is a powerful tool and it enables more complex visualization.
Moreover, it is optimized to analyze large data sets spreed over several dimensions and provides powerful selection operators that can be used to do conditional zoom and filtering.
Using \gls{R}, we have provided several meaningful plots that can be used to start a memory trace analysis
These visualization could be used to compare the memory access patterns of applications in order to understand the underlying algorithm of proprietary programs such as the \gls{MKL}.

Another approach that have not been studied during this thesis would be to analyze traces automatically.
Such analysis would have to detect memory patterns and possibly and highlight parts of code that should be improved.
A memory pattern is an interaction between threads inside a memory area over a short laps of time.
Yet, defining such a pattern in a more specific way is a hard task.

For any approach, it appears that the developers knowledge is useful to focus the analysis on the interesting parts.
Therefore we need a way to use this knowledge during the analysis and as soon as possible to reduce the amount of data to analyze.
Nerveless, we have seen in \chap{perf} that they might not know all the sources of performance issues.
In the end, this knowledge can be used to focus the analysis but it is important to also have a global visualization of the trace, to spot issue that would have been missed by the developers.
Hence the two approaches described in this chapter can be used in a complementary way.
% vim: et si sta lbr  sw=4 ts=4 spelllang=en_us
